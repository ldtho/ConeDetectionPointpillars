{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caroline-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pandas\n",
    "import sys\n",
    "\n",
    "sys.path.append('/kaggle/code/ConeDetectionPointpillars')\n",
    "import fire\n",
    "import pickle\n",
    "import json\n",
    "from lyft_dataset_sdk.utils.geometry_utils import quaternion_yaw\n",
    "from second.data.dataset import Dataset, register_dataset, get_dataset_class\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from nuscenes.utils.geometry_utils import transform_matrix, view_points\n",
    "from second.core import box_np_ops\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from nuscenes.nuscenes import NuScenesExplorer\n",
    "# VERSION = 'trainval'\n",
    "# TRAINVAL_SPLIT_PERCENTAGE = 0.99 if VERSION == 'trainval' else 0.8\n",
    "# MIN_CONES_PER_SAMPLE = 8\n",
    "# NameMapping = {\n",
    "#     'movable_object.barrier': 'barrier',\n",
    "#     'vehicle.bicycle': 'bicycle',\n",
    "#     'vehicle.bus.bendy': 'bus',\n",
    "#     'vehicle.bus.rigid': 'bus',\n",
    "#     'vehicle.car': 'car',\n",
    "#     'vehicle.construction': 'construction_vehicle',\n",
    "#     'vehicle.motorcycle': 'motorcycle',\n",
    "#     'human.pedestrian.adult': 'pedestrian',\n",
    "#     'human.pedestrian.child': 'pedestrian',\n",
    "#     'human.pedestrian.construction_worker': 'pedestrian',\n",
    "#     'human.pedestrian.police_officer': 'pedestrian',\n",
    "#     'movable_object.trafficcone': 'traffic_cone',\n",
    "#     'vehicle.trailer': 'trailer',\n",
    "#     'vehicle.truck': 'truck',\n",
    "#     'movable_object.pushable_pullable': 'DontCare',\n",
    "#     'movable_object.debris': 'DontCare'\n",
    "# }\n",
    "\n",
    "# DefaultAttribute = {\n",
    "#     \"car\": \"vehicle.parked\",\n",
    "#     \"pedestrian\": \"pedestrian.moving\",\n",
    "#     \"trailer\": \"vehicle.parked\",\n",
    "#     \"truck\": \"vehicle.parked\",\n",
    "#     \"bus\": \"vehicle.parked\",\n",
    "#     \"motorcycle\": \"cycle.without_rider\",\n",
    "#     \"construction_vehicle\": \"vehicle.parked\",\n",
    "#     \"bicycle\": \"cycle.without_rider\",\n",
    "#     \"barrier\": \"\",\n",
    "#     \"traffic_cone\": \"\",\n",
    "# }\n",
    "\n",
    "\n",
    "# @register_dataset\n",
    "# class CustomNuscDataset(Dataset):\n",
    "#     NumPointFeatures = 5\n",
    "\n",
    "#     def __init__(self, root_path=f'/media/starlet/LdTho/data/sets/nuscenes/v1.0-{VERSION}', info_path=None,\n",
    "#                  class_names=[\"traffic_cone\"], prep_func=None,\n",
    "#                  num_point_features=None):\n",
    "#         self.NumPointFeatures = 5\n",
    "#         self.class_names = class_names\n",
    "#         self.nusc = NuScenes(dataroot=root_path, version=f'v1.0-{VERSION}')\n",
    "#         self._prep_func = prep_func\n",
    "#         self.filtered_sample_tokens = []\n",
    "#         for sample in self.nusc.sample:\n",
    "#             sample_token = sample['token']\n",
    "#             sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "#             boxes = self.nusc.get_boxes(sample_lidar_token)\n",
    "#             box_names = [NameMapping[b.name] for b in boxes if b.name in NameMapping.keys()]\n",
    "#             for box in boxes:\n",
    "#                 if box.name not in NameMapping.keys():\n",
    "#                     continue\n",
    "#                 # if NameMapping[box.name] in self.class_names:\n",
    "#                 if (NameMapping[box.name] in [\"traffic_cone\"]) & (\n",
    "#                         box_names.count('traffic_cone') > MIN_CONES_PER_SAMPLE):\n",
    "#                     self.filtered_sample_tokens.append(sample_token)\n",
    "#                     break\n",
    "#         self.filtered_sample_tokens = self.filtered_sample_tokens[\n",
    "#                                       :round(len(self.filtered_sample_tokens) * TRAINVAL_SPLIT_PERCENTAGE)]\n",
    "\n",
    "#         self.split = np.arange(len(self.filtered_sample_tokens))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.split.shape[0]\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         input_dict = self.get_sensor_data(index)\n",
    "#         example = self._prep_func(input_dict=input_dict)\n",
    "#         example[\"metadata\"] = input_dict[\"metadata\"]\n",
    "#         if \"anchors_mask\" in example:\n",
    "#             example[\"anchors_mask\"] = example[\"anchors_mask\"].astype(np.uint8)\n",
    "#         return example\n",
    "\n",
    "#     def get_sensor_data(self, query, token=None):\n",
    "#         res = {\n",
    "#             'lidar': {\n",
    "#                 'type': 'lidar',\n",
    "#                 'points': None,\n",
    "#             },\n",
    "#             'metadata': {\n",
    "#                 'token': self.filtered_sample_tokens[query]\n",
    "#             }\n",
    "#         }\n",
    "#         if token:\n",
    "#             query = self.filtered_sample_tokens.index(token)\n",
    "#         points = self.getPoints(query)\n",
    "#         boxes_dict = self.getBoxes(query)\n",
    "\n",
    "#         res['lidar']['points'] = points\n",
    "\n",
    "#         gt_boxes = []\n",
    "#         gt_names = []\n",
    "\n",
    "#         for box in boxes_dict:\n",
    "#             xyz = box.center\n",
    "#             wlh = box.wlh\n",
    "#             theta = quaternion_yaw(box.orientation)\n",
    "#             gt_boxes.append([xyz[0], xyz[1], xyz[2], wlh[0], wlh[1], wlh[2], -theta - np.pi / 2])\n",
    "#             gt_names.append(box.name)\n",
    "#         gt_boxes = np.concatenate(gt_boxes).reshape(-1, 7)\n",
    "#         gt_names = np.array(gt_names)\n",
    "#         res['lidar']['annotations'] = {\n",
    "#             'boxes': gt_boxes,\n",
    "#             'names': gt_names,\n",
    "#         }\n",
    "#         return res\n",
    "\n",
    "#         ###\n",
    "\n",
    "#     def getPoints(self, index):\n",
    "#         sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "#         sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "\n",
    "#         lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "#         ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "#         calibrated_sensor = self.nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "\n",
    "#         global_from_car = transform_matrix(ego_pose['translation'],\n",
    "#                                            Quaternion(ego_pose['rotation']), inverse=False)\n",
    "#         car_from_sensor = transform_matrix(calibrated_sensor['translation'],\n",
    "#                                            Quaternion(calibrated_sensor['rotation']), inverse=False)\n",
    "#         try:\n",
    "#             lidar_pointcloud, times = LidarPointCloud.from_file_multisweep(self.nusc, sample, 'LIDAR_TOP',\n",
    "#                                                                            'LIDAR_TOP')\n",
    "#             lidar_pointcloud.transform(car_from_sensor)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to load Lidar Pointcloud for {sample}:{e}\")\n",
    "#         points = lidar_pointcloud.points\n",
    "#         print(points)\n",
    "#         points[3, :] /= 255\n",
    "#         points[3, :] -= 0.5\n",
    "\n",
    "#         points_cat = np.concatenate([points, times], axis=0).transpose()\n",
    "#         print(points_cat)\n",
    "#         points_cat = points_cat[~np.isnan(points_cat).any(axis=1)]\n",
    "\n",
    "#         return points_cat\n",
    "\n",
    "#     def getBoxes(self, index):\n",
    "\n",
    "#         sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "#         sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "#         lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "#         ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "\n",
    "#         boxes_dict = self.nusc.get_boxes(sample_lidar_token)\n",
    "\n",
    "#         keep_box_idx = []\n",
    "#         for i, box in enumerate(boxes_dict):\n",
    "#             if box.name not in NameMapping.keys():\n",
    "#                 continue\n",
    "#             if NameMapping[box.name] in self.class_names:\n",
    "#                 box.name = NameMapping[box.name]\n",
    "#                 keep_box_idx.append(i)\n",
    "\n",
    "#         boxes_dict = [box for i, box in enumerate(boxes_dict) if i in keep_box_idx]\n",
    "#         self.move_boxes_to_car_space(boxes_dict, ego_pose)\n",
    "#         # print(boxes_dict)\n",
    "#         return boxes_dict\n",
    "\n",
    "#     def move_boxes_to_car_space(self, boxes, ego_pose):\n",
    "#         \"\"\"\n",
    "#         Move boxes from world space to car space.\n",
    "#         Note: mutates input boxes.\n",
    "#         \"\"\"\n",
    "#         translation = -np.array(ego_pose['translation'])\n",
    "#         rotation = Quaternion(ego_pose['rotation']).inverse\n",
    "\n",
    "#         for box in boxes:\n",
    "#             # Bring box to car space\n",
    "#             box.translate(translation)\n",
    "#             box.rotate(rotation)\n",
    "\n",
    "\n",
    "# @register_dataset\n",
    "# class CustomNuscTestDataset(Dataset):\n",
    "#     NumPointFeatures = 5\n",
    "\n",
    "#     def __init__(self, root_path=f'/media/starlet/LdTho/data/sets/nuscenes/v1.0-{VERSION}',\n",
    "#                  info_path=None,\n",
    "#                  class_names=['traffic_cone'],\n",
    "#                  prep_func=None,\n",
    "#                  num_point_features=None,\n",
    "#                  multi_test=False):\n",
    "#         print(root_path)\n",
    "#         self.nusc = NuScenes(dataroot=root_path, version=f'v1.0-{VERSION}')\n",
    "#         self.class_names = class_names\n",
    "#         self._prep_func = prep_func\n",
    "#         self.filtered_sample_tokens = []\n",
    "#         self.multi_test = multi_test\n",
    "#         for sample in self.nusc.sample:\n",
    "#             sample_token = sample['token']\n",
    "#             sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "#             boxes = self.nusc.get_boxes(sample_lidar_token)\n",
    "#             for box in boxes:\n",
    "#                 # self.box_classes.add(box.name\n",
    "#                 if box.name not in NameMapping.keys():\n",
    "#                     continue\n",
    "#                 if NameMapping[box.name] in self.class_names:\n",
    "#                     self.filtered_sample_tokens.append(sample_token)\n",
    "#                     break\n",
    "#         self.filtered_sample_tokens = self.filtered_sample_tokens[\n",
    "#                                       round(len(self.filtered_sample_tokens) * TRAINVAL_SPLIT_PERCENTAGE):]\n",
    "#         self.split = np.arange(len(self.filtered_sample_tokens))\n",
    "#         self.num_samples = len(self.filtered_sample_tokens)\n",
    "#         self.rot = 0.0\n",
    "#         self.scale = 1.0\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.num_samples\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         input_dict = self.get_sensor_data(index)\n",
    "#         example = self._prep_func(input_dict=input_dict)\n",
    "#         example[\"metadata\"] = input_dict[\"metadata\"]\n",
    "#         if \"anchors_mask\" in example:\n",
    "#             example[\"anchors_mask\"] = example[\"anchors_mask\"].astype(np.uint8)\n",
    "#         return example\n",
    "\n",
    "#     def get_sensor_data(self, query):\n",
    "#         res = {\n",
    "#             'lidar': {\n",
    "#                 'type': 'lidar',\n",
    "#                 'points': None\n",
    "#             },\n",
    "#             'metadata': {\n",
    "#                 'token': self.filtered_sample_tokens[query],\n",
    "#             }\n",
    "#         }\n",
    "#         points = self.getPoints(query)\n",
    "#         res['lidar']['points'] = points\n",
    "#         return res\n",
    "\n",
    "#     def getPoints(self, query):\n",
    "#         sample = self.nusc.get('sample', self.filtered_sample_tokens[query])\n",
    "#         sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "\n",
    "#         lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "#         ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "#         calibrated_sensor = self.nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "\n",
    "#         global_from_car = transform_matrix(ego_pose['translation'],\n",
    "#                                            Quaternion(ego_pose['rotation']), inverse=False)\n",
    "#         car_from_sensor = transform_matrix(calibrated_sensor['translation'],\n",
    "#                                            Quaternion(calibrated_sensor['rotation']), inverse=False)\n",
    "#         try:\n",
    "#             lidar_pointcloud, times = LidarPointCloud.from_file_multisweep(self.nusc, sample, 'LIDAR_TOP', 'LIDAR_TOP')\n",
    "#             lidar_pointcloud.transform(car_from_sensor)\n",
    "#         except Exception as e:\n",
    "#             print(f\"failed to load pointcloud for {sample}: {e}\")\n",
    "#         points = lidar_pointcloud.points\n",
    "#         points[3, :] /= 255\n",
    "#         points[3, :] -= 0.5\n",
    "#         points_cat = np.concatenate([points, times], axis=0).transpose()\n",
    "#         points_cat = points_cat[~np.isnan(points_cat).any(axis=1)]\n",
    "#         return points_cat\n",
    "\n",
    "#     def evaluation(self, detections, output_dir):\n",
    "#         res_custom_nusc = self.evaluation_custom_nusc(detections, output_dir)\n",
    "#         res = {\n",
    "#             \"results\": {\n",
    "#                 \"nusc\": res_custom_nusc[\"results\"][\"nusc\"],\n",
    "#             },\n",
    "#             \"details\": {\n",
    "#                 \"eval.nusc\": res_custom_nusc[\"detail\"][\"nusc\"]\n",
    "#             }\n",
    "#         }\n",
    "#         return res\n",
    "\n",
    "#     def evaluation_custom_nusc(self, detections, output_dir):\n",
    "#         pass\n",
    "\n",
    "\n",
    "# # should shorten by inherit from parent class CustomNuscDataset\n",
    "# EVAL_VERSION = 'mini'\n",
    "\n",
    "\n",
    "# @register_dataset\n",
    "# class CustomNuscEvalDataset(Dataset):\n",
    "#     NumPointFeatures = 5\n",
    "\n",
    "#     def __init__(self, root_path=f'/media/starlet/LdTho/data/sets/nuscenes/v1.0-{EVAL_VERSION}', info_path=None,\n",
    "#                  class_names=[\"traffic_cone\"], prep_func=None,\n",
    "#                  num_point_features=None):\n",
    "#         self.NumPointFeatures = 5\n",
    "#         self.class_names = class_names\n",
    "#         self.nusc = NuScenes(dataroot=root_path, version=f'v1.0-{EVAL_VERSION}')\n",
    "#         self._prep_func = prep_func\n",
    "#         self.root_path = root_path\n",
    "#         self.eval_version = \"detection_cvpr_2019\"\n",
    "#         # self.filtered_sample_tokens = [s['token'] for s in self.nusc.sample]\n",
    "\n",
    "#         self.filtered_sample_tokens = []\n",
    "#         for sample in self.nusc.sample:\n",
    "#             sample_token = sample['token']\n",
    "#             sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "#             boxes = self.nusc.get_boxes(sample_lidar_token)\n",
    "#             box_names = [NameMapping[b.name] for b in boxes if b.name in NameMapping.keys()]\n",
    "#             for box in boxes:\n",
    "#                 if box.name not in NameMapping.keys():\n",
    "#                     continue\n",
    "#                 # if NameMapping[box.name] in self.class_names:\n",
    "#                 if (NameMapping[box.name] in [\"traffic_cone\"]) & (\n",
    "#                         box_names.count('traffic_cone') > MIN_CONES_PER_SAMPLE):\n",
    "#                     self.filtered_sample_tokens.append(sample_token)\n",
    "#                     break\n",
    "#         if EVAL_VERSION == \"trainval\":\n",
    "#             self.filtered_sample_tokens = self.filtered_sample_tokens[\n",
    "#                                           round(len(self.filtered_sample_tokens) * TRAINVAL_SPLIT_PERCENTAGE):]\n",
    "\n",
    "#         self.split = np.arange(len(self.filtered_sample_tokens))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.split.shape[0]\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         input_dict = self.get_sensor_data(index)\n",
    "#         example = self._prep_func(input_dict=input_dict)\n",
    "#         example[\"metadata\"] = input_dict[\"metadata\"]\n",
    "#         if \"anchors_mask\" in example:\n",
    "#             example[\"anchors_mask\"] = example[\"anchors_mask\"].astype(np.uint8)\n",
    "#         return example\n",
    "\n",
    "#     def get_sensor_data(self, query, token=None):\n",
    "#         res = {\n",
    "#             'lidar': {\n",
    "#                 'type': 'lidar',\n",
    "#                 'points': None,\n",
    "#             },\n",
    "#             'metadata': {\n",
    "#                 'token': self.filtered_sample_tokens[query]\n",
    "#             }\n",
    "#         }\n",
    "#         if token:\n",
    "#             query = self.filtered_sample_tokens.index(token)\n",
    "#         points = self.getPoints(query)\n",
    "#         boxes_dict = self.getBoxes(query)\n",
    "\n",
    "#         res['lidar']['points'] = points\n",
    "\n",
    "#         gt_boxes = []\n",
    "#         gt_names = []\n",
    "\n",
    "#         for box in boxes_dict:\n",
    "#             xyz = box.center\n",
    "#             wlh = box.wlh\n",
    "#             theta = quaternion_yaw(box.orientation)\n",
    "#             gt_boxes.append([xyz[0], xyz[1], xyz[2], wlh[0], wlh[1], wlh[2], -theta - np.pi / 2])\n",
    "#             gt_names.append(box.name)\n",
    "#         gt_boxes = np.concatenate(gt_boxes).reshape(-1, 7)\n",
    "#         gt_names = np.array(gt_names)\n",
    "#         res['lidar']['annotations'] = {\n",
    "#             'boxes': gt_boxes,\n",
    "#             'names': gt_names,\n",
    "#         }\n",
    "#         return res\n",
    "\n",
    "#         ###\n",
    "\n",
    "#     def getPoints(self, index):\n",
    "#         sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "#         sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "\n",
    "#         lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "#         ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "#         calibrated_sensor = self.nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "\n",
    "#         global_from_car = transform_matrix(ego_pose['translation'],\n",
    "#                                            Quaternion(ego_pose['rotation']), inverse=False)\n",
    "#         car_from_sensor = transform_matrix(calibrated_sensor['translation'],\n",
    "#                                            Quaternion(calibrated_sensor['rotation']), inverse=False)\n",
    "#         try:\n",
    "#             lidar_pointcloud, times = LidarPointCloud.from_file_multisweep(self.nusc, sample, 'LIDAR_TOP',\n",
    "#                                                                            'LIDAR_TOP')\n",
    "#             lidar_pointcloud.transform(car_from_sensor)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to load Lidar Pointcloud for {sample}:{e}\")\n",
    "#         points = lidar_pointcloud.points\n",
    "#         points[3, :] /= 255\n",
    "#         points[3, :] -= 0.5\n",
    "\n",
    "#         points_cat = np.concatenate([points, times], axis=0).transpose()\n",
    "#         points_cat = points_cat[~np.isnan(points_cat).any(axis=1)]\n",
    "\n",
    "#         return points_cat\n",
    "\n",
    "#     def getBoxes(self, index):\n",
    "\n",
    "#         sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "#         sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "#         lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "#         ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "\n",
    "#         boxes_dict = self.nusc.get_boxes(sample_lidar_token)\n",
    "\n",
    "#         keep_box_idx = []\n",
    "#         for i, box in enumerate(boxes_dict):\n",
    "#             if box.name not in NameMapping.keys():\n",
    "#                 continue\n",
    "#             if NameMapping[box.name] in self.class_names:\n",
    "#                 box.name = NameMapping[box.name]\n",
    "#                 keep_box_idx.append(i)\n",
    "\n",
    "#         boxes_dict = [box for i, box in enumerate(boxes_dict) if i in keep_box_idx]\n",
    "#         self.move_boxes_to_car_space(boxes_dict, ego_pose)\n",
    "#         # print(boxes_dict)\n",
    "#         return boxes_dict\n",
    "\n",
    "#     def move_boxes_to_car_space(self, boxes, ego_pose, eval = False):\n",
    "#         \"\"\"\n",
    "#         Move boxes from world space to car space.\n",
    "#         Note: mutates input boxes.\n",
    "#         \"\"\"\n",
    "#         translation = -np.array(ego_pose['translation'])\n",
    "#         rotation = Quaternion(ego_pose['rotation']).inverse\n",
    "#         box_list = []\n",
    "#         for box in boxes:\n",
    "#             # Bring box to car space\n",
    "#             box.translate(translation)\n",
    "#             box.rotate(rotation)\n",
    "#             box_list.append(box)\n",
    "#         return box_list\n",
    "\n",
    "#     def evaluation(self, detections, output_dir):\n",
    "#         \"\"\"kitti evaluation is very slow, remove it.\n",
    "#         \"\"\"\n",
    "#         # res_kitti = self.evaluation_kitti(detections, output_dir)\n",
    "#         res_nusc = self.evaluation_nusc(detections, output_dir)\n",
    "#         res = {\n",
    "#             \"results\": {\n",
    "#                 \"nusc\": res_nusc[\"results\"][\"nusc\"],\n",
    "#                 # \"kitti.official\": res_kitti[\"results\"][\"official\"],\n",
    "#                 # \"kitti.coco\": res_kitti[\"results\"][\"coco\"],\n",
    "#             },\n",
    "#             \"detail\": {\n",
    "#                 \"eval.nusc\": res_nusc[\"detail\"][\"nusc\"],\n",
    "#                 # \"eval.kitti\": {\n",
    "#                 #     \"official\": res_kitti[\"detail\"][\"official\"],\n",
    "#                 #     \"coco\": res_kitti[\"detail\"][\"coco\"],\n",
    "#                 # },\n",
    "#             },\n",
    "#         }\n",
    "#         return res\n",
    "\n",
    "#     def evaluation_nusc(self, detections, output_dir):\n",
    "#         mapped_class_names = self.class_names\n",
    "#         nusc_annos = {}\n",
    "#         token2info = {}\n",
    "#         for det in detections:\n",
    "#             annos = []\n",
    "#             boxes = _second_det_to_nusc_box(det)\n",
    "#             boxes = self.transform_box_back_to_global(boxes, det[\"metadata\"][\"token\"])\n",
    "\n",
    "#             # boxes = self.move_boxes_to_car_space(boxes, ego_pose)\n",
    "#             for i, box in enumerate(boxes):\n",
    "#                 name = mapped_class_names[box.label]\n",
    "#                 velocity = [np.nan, np.nan]\n",
    "#                 nusc_anno = {\n",
    "#                     \"sample_token\": det[\"metadata\"][\"token\"],\n",
    "#                     \"translation\": box.center.tolist(),\n",
    "#                     \"size\": box.wlh.tolist(),\n",
    "#                     \"rotation\": box.orientation.elements.tolist(),\n",
    "#                     \"velocity\": velocity,\n",
    "#                     \"detection_name\": name,\n",
    "#                     \"detection_score\": box.score,\n",
    "#                     \"attribute_name\": DefaultAttribute[name]\n",
    "#                 }\n",
    "#                 annos.append(nusc_anno)\n",
    "#             nusc_annos[det[\"metadata\"][\"token\"]] = annos\n",
    "#         nusc_submissions = {\n",
    "#             \"meta\": {\n",
    "#                 \"use_camera\": False,\n",
    "#                 \"use_lidar\": False,\n",
    "#                 \"use_radar\": False,\n",
    "#                 \"use_map\": False,\n",
    "#                 \"use_external\": False\n",
    "#             },\n",
    "#             \"results\": nusc_annos\n",
    "#         }\n",
    "#         res_path = Path(output_dir) / \"result_nusc.json\"\n",
    "#         with open(res_path, \"w\") as f:\n",
    "#             json.dump(nusc_submissions, f)\n",
    "#         eval_main_file = Path(__file__).resolve().parent / \"nusc_eval.py\"\n",
    "#         cmd = f\"python {str(eval_main_file)} --root_path=\\\"{self.root_path}\\\"\"\n",
    "#         cmd += f\" --version=\\\"v1.0-mini\\\" --eval_version={self.eval_version}\"\n",
    "#         cmd += f\" --res_path=\\\"{str(res_path)}\\\" --eval_set=mini_train\"\n",
    "#         cmd += f\" --output_dir=\\\"{output_dir}\\\"\"\n",
    "#         print(cmd)\n",
    "#         subprocess.check_output(cmd, shell=True)\n",
    "#         with open(Path(output_dir) / \"metrics_summary.json\", \"r\") as f:\n",
    "#             metrics = json.load(f)\n",
    "#         detail = {}\n",
    "#         res_path.unlink()\n",
    "#         result = f\"Nusc {VERSION} evaluation\"\n",
    "#         for name in mapped_class_names:\n",
    "#             detail[name] = {}\n",
    "#             for k, v in metrics[\"label_aps\"][name].items():\n",
    "#                 detail[name][f\"dist@{k}\"] = v\n",
    "#             tp_errs = []\n",
    "#             tp_names = []\n",
    "#             for k, v in metrics[\"label_tp_errors\"][name].items():\n",
    "#                 detail[name][k] = v\n",
    "#                 tp_errs.append(f\"{v:.4f}\")\n",
    "#                 tp_names.append(k)\n",
    "#             threshs = ', '.join(list(metrics[\"label_aps\"][name].keys()))\n",
    "#             scores = list(metrics[\"label_aps\"][name].values())\n",
    "#             scores = ', '.join([f\"{s * 100:.2f}\" for s in scores])\n",
    "#             result += f\"{name} Nusc dist AP@{threshs} and TP errors\\n\"\n",
    "#             result += scores\n",
    "#             result += ', '.join(tp_names) + \": \" + \", \".join(tp_errs)\n",
    "#             result += \"\\n\"\n",
    "#         return {\n",
    "#             \"results\": {\n",
    "#                 \"nusc\": result,\n",
    "#             },\n",
    "#             \"detail\": {\n",
    "#                 \"nusc\": detail\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#     def transform_box_back_to_global(self, boxes, token):\n",
    "#         sample = self.nusc.get('sample', token)\n",
    "#         sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "#         lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "#         ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "\n",
    "#         translation = np.array(ego_pose['translation'])\n",
    "#         rotation = Quaternion(ego_pose['rotation'])\n",
    "#         box_list = []\n",
    "#         for box in boxes:\n",
    "#             box.rotate(rotation)\n",
    "#             box.translate(translation)\n",
    "#             box_list.append(box)\n",
    "#         return box_list\n",
    "\n",
    "\n",
    "# def _second_det_to_nusc_box(detection):\n",
    "#     from nuscenes.utils.data_classes import Box\n",
    "#     import pyquaternion\n",
    "#     box3d = detection[\"box3d_lidar\"].detach().cpu().numpy()\n",
    "#     scores = detection[\"scores\"].detach().cpu().numpy()\n",
    "#     labels = detection[\"label_preds\"].detach().cpu().numpy()\n",
    "#     box3d[:, 6] = -box3d[:, 6] - np.pi / 2\n",
    "#     box_list = []\n",
    "#     for i in range(box3d.shape[0]):\n",
    "#         quat = pyquaternion.Quaternion(axis=[0, 0, 1], radians=box3d[i, 6])\n",
    "#         velocity = (np.nan, np.nan, np.nan)\n",
    "#         if box3d.shape[1] == 9:\n",
    "#             velocity = (*box3d[i, 7:9], 0.0)\n",
    "#             # velo_val = np.linalg.norm(box3d[i, 7:9])\n",
    "#             # velo_ori = box3d[i, 6]\n",
    "#             # velocity = (velo_val * np.cos(velo_ori), velo_val * np.sin(velo_ori), 0.0)\n",
    "#         box = Box(\n",
    "#             box3d[i, :3],\n",
    "#             box3d[i, 3:6],\n",
    "#             quat,\n",
    "#             label=labels[i],\n",
    "#             score=scores[i],\n",
    "#             velocity=velocity)\n",
    "#         box_list.append(box)\n",
    "#     return box_list\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     fire.Fire()\n",
    "#     # train_data = CustomNuscDataset()\n",
    "#     # test_data = CustomNuscTestDataset(root_path='/media/starlet/LdTho/data/sets/nuscenes/v1.0-trainval',\n",
    "#     #                                   )\n",
    "# #     print(train_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "missing-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path=Path(f'/media/starlet/LdTho/data/sets/lidarsim')\n",
    "info_path=None\n",
    "class_names=[\"traffic_cone\"]\n",
    "prep_func=None\n",
    "num_point_features=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "experienced-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import open3d as o3d\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "coated-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [re.match(r\"\\d+\",file)[0] for file in listdir(root_path) if file.endswith('.pcd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "occupied-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = '1612769426131975'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "alert-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(root_path)/f\"{sample}.pcd\"\n",
    "pcd = o3d.io.read_point_cloud(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "controlled-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array(pcd.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "integral-palestinian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25499, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "optical-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_path = root_path / f\"{sample}.txt\"\n",
    "boxes = pd.read_csv(str(box_path), delimiter = ' ', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "average-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_list = [list(box) for _, box in boxes.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "tight-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['traffic_cone', 0.0, 0, -1.57, 599.41, 156.4, 629.75, 189.25, 2.85, 2.63, 12.34, 0.47, 1.49, 69.44, -1.56]\n"
     ]
    }
   ],
   "source": [
    "print(box_list[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
