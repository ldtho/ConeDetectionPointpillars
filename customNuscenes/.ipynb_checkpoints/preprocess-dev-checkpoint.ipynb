{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "from lyft_dataset_sdk.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix, quaternion_yaw\n",
    "import numpy as np\n",
    "import pandas as pandas\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.8 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACTS_FOLDER = './lyft_custom_artifacts'\n",
    "LYFT_DATASET_ROOT = '/kaggle/input/3d-object-detection-for-autonomous-vehicles'\n",
    "level5data = LyftDataset(data_path=DATA_PATH, json_path= os.path.join(DATA_PATH, 'train_data'))\n",
    "os.makedirs(ARTIFACTS_FOLDER, exist_ok = True)\n",
    "classes = ['car', 'motorcycle', 'bus', 'bicycle', 'truck', 'pedestrian', 'other_vehicle', 'animal', 'emergency_vehicle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level5data.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CLASSES = ['truck']\n",
    "filtered_sample_token = []\n",
    "for sample in tqdm_notebook(level5data.sample):\n",
    "    sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "    boxes = level5data.get_boxes(sample_lidar_token)\n",
    "    for box in boxes:\n",
    "        if box.name in TARGET_CLASSES:\n",
    "            filtered_sample_token.append(sample['token'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = filtered_sample_token[:round(len(filtered_sample_token)*0.8)]\n",
    "valid_samples = filtered_sample_token[round(len(filtered_sample_token)*0.8):]\n",
    "len(valid_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level5data.get('sample', train_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_folder = os.path.join(ARTIFACTS_FOLDER, \"samples_train\")\n",
    "valid_data_folder = os.path.join(ARTIFACTS_FOLDER, \"samples_valid\")\n",
    "for samples, folder in [(train_samples, train_data_folder), (valid_samples, valid_data_folder)]:\n",
    "    os.makedir(folder, exist_ok = True)\n",
    "    for sample_token in tqdm_notebook(samples):\n",
    "        sample = level5data.get('sample', sample_token)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/kaggle/code/lyft-tho')\n",
    "from second.data.dataset import Dataset, register_dataset\n",
    "LYFT_DATASET_ROOT = '/kaggle/input/3d-object-detection-for-autonomous-vehicles'\n",
    "\n",
    "# @register_dataset\n",
    "class CustomLyftDataset(Dataset):\n",
    "    NumPointFeatures = 5\n",
    "\n",
    "    def __init__(self, root_path=LYFT_DATASET_ROOT, info_path=None,\n",
    "                 class_names=None, prep_func=None,\n",
    "                 num_point_features=None):\n",
    "\n",
    "        data_dir = root_path\n",
    "        json_dir = os.path.join(root_path, 'train_data')\n",
    "        self.class_names = class_names\n",
    "        self.lyft = LyftDataset(data_path=data_dir, json_path=json_dir)\n",
    "        self._prep_func = prep_func\n",
    "\n",
    "        self.filtered_sample_tokens = []\n",
    "        for sample in self.lyft.sample:\n",
    "            sample_token = sample['token']\n",
    "            sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "            boxes = self.lyft.get_boxes(sample_lidar_token)\n",
    "            for box in boxes:\n",
    "                if box.name in self.class_names:\n",
    "                    self.filtered_sample_tokens.append(sample_token)\n",
    "                    break\n",
    "\n",
    "        self.split = np.arange(len(self.filtered_sample_tokens))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.split.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_dict = self.get_sensor_data(index)\n",
    "        try:\n",
    "            example = self._prep_func(input_dict=input_dict)\n",
    "            return example\n",
    "        except:\n",
    "            return input_dict\n",
    "\n",
    "    def get_sensor_data(self, query):\n",
    "        res = {\n",
    "            'lidar': {\n",
    "                'type': 'lidar',\n",
    "                'points': None,\n",
    "            },\n",
    "            'metadata': {\n",
    "                'token': self.filtered_sample_tokens[query]\n",
    "            }\n",
    "        }\n",
    "        points = self.getPoints(query)\n",
    "        boxes_dict = self.getBoxes(query)\n",
    "\n",
    "        res['lidar']['points'] = points\n",
    "\n",
    "        gt_boxes = []\n",
    "        gt_names = []\n",
    "\n",
    "        for box in boxes_dict:\n",
    "            xyz = box.center\n",
    "            wlh = box.wlh\n",
    "            theta = quaternion_yaw(box.orientation)\n",
    "            gt_boxes.append([xyz[0], xyz[1], xyz[2], wlh[0], wlh[1], wlh[2], -theta - np.pi / 2])\n",
    "            gt_names.append(box.name)\n",
    "\n",
    "        res['lidar']['annotation'] = {\n",
    "            'boxes': gt_boxes,\n",
    "            'names': gt_names,\n",
    "        }\n",
    "        return res\n",
    "\n",
    "        ###\n",
    "\n",
    "    def getPoints(self, index):\n",
    "        sample = self.lyft.get('sample', self.filtered_sample_tokens[index])\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "\n",
    "        lidar_data = self.lyft.get('sample_data', sample_lidar_token)\n",
    "        ego_pose = self.lyft.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "        calibrated_sensor = self.lyft.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "\n",
    "        global_from_car = transform_matrix(ego_pose['translation'],\n",
    "                                           Quaternion(ego_pose['rotation']), inverse=False)\n",
    "        car_from_sensor = transform_matrix(calibrated_sensor['translation'],\n",
    "                                           Quaternion(calibrated_sensor['rotation']), inverse=False)\n",
    "        try:\n",
    "            lidar_pointcloud, times = LidarPointCloud.from_file_multisweep(self.lyft, sample, 'LIDAR_TOP',\n",
    "                                                                           'LIDAR_TOP', num_sweeps=10)\n",
    "            lidar_pointcloud.transform(car_from_sensor)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load Lidar Pointcloud for {sample}:{e}\")\n",
    "        points = lidar_pointcloud.points\n",
    "        points[3, :] /= 255\n",
    "        points[3, :] -= 0.5\n",
    "\n",
    "        points_cat = np.concatenate([points, times], axis=0).transpose()\n",
    "        points_cat = points_cat[~np.isnan(points_cat).any(axis=1)]\n",
    "\n",
    "        return points_cat\n",
    "\n",
    "    def getBoxes(self, index):\n",
    "\n",
    "        sample = self.lyft.get('sample', self.filtered_sample_tokens[index])\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "        lidar_data = self.lyft.get('sample_data', sample_lidar_token)\n",
    "        ego_pose = self.lyft.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "\n",
    "        boxes_dict = self.lyft.get_boxes(sample_lidar_token)\n",
    "\n",
    "        keep_box_idx = []\n",
    "        for i, box in enumerate(boxes_dict):\n",
    "            if box.name in self.class_names:\n",
    "                keep_box_idx.append(i)\n",
    "\n",
    "        boxes_dict = [box for i, box in enumerate(boxes_dict) if i in keep_box_idx]\n",
    "\n",
    "        return boxes_dict\n",
    "\n",
    "    def move_boxes_to_car_space(self,boxes, ego_pose):\n",
    "        \"\"\"\n",
    "        Move boxes from world space to car space.\n",
    "        Note: mutates input boxes.\n",
    "        \"\"\"\n",
    "        translation = -np.array(ego_pose['translation'])\n",
    "        rotation = Quaternion(ego_pose['rotation']).inverse\n",
    "\n",
    "        for box in boxes:\n",
    "            # Bring box to car space\n",
    "            box.translate(translation)\n",
    "            box.rotate(rotation)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CustomLyftDataset(class_names = 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level5data.render_sample_data(\n",
    "    level5data.get('sample',a[5]['metadata']['token'])['data']['LIDAR_TOP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "# from lyft_dataset_sdk.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "import sys\n",
    "sys.path.append('/kaggle/code/lyft-tho')\n",
    "\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix, quaternion_yaw\n",
    "from second.data.dataset import Dataset, register_dataset\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from nuscenes.utils.geometry_utils import *\n",
    "import numpy as np\n",
    "import pandas as pandas\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "\n",
    "\n",
    "LYFT_DATASET_ROOT = '/kaggle/input/3d-object-detection-for-autonomous-vehicles'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pandas\n",
    "sys.path.append('/kaggle/code/lyft-tho')\n",
    "import fire\n",
    "import pickle\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix, quaternion_yaw\n",
    "from second.data.dataset import Dataset, register_dataset,get_dataset_class\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from nuscenes.utils.geometry_utils import *\n",
    "\n",
    "VERSION = 'trainval'\n",
    "NUSC_DATASET_ROOT = f'/media/starlet/LdTho/data/sets/nuscenes/v1.0-{VERSION}'\n",
    "OBJECT_CLASSES = ['animal',\n",
    "                  'human.pedestrian.adult',\n",
    "                  'human.pedestrian.child',\n",
    "                  'human.pedestrian.construction_worker',\n",
    "                  'human.pedestrian.personal_mobility',\n",
    "                  'human.pedestrian.police_officer',\n",
    "                  'human.pedestrian.stroller',\n",
    "                  'human.pedestrian.wheelchair',\n",
    "                  'movable_object.barrier',\n",
    "                  'movable_object.debris',\n",
    "                  'movable_object.pushable_pullable',\n",
    "                  'movable_object.trafficcone',\n",
    "                  'static_object.bicycle_rack',\n",
    "                  'vehicle.bicycle',\n",
    "                  'vehicle.bus.bendy',\n",
    "                  'vehicle.bus.rigid',\n",
    "                  'vehicle.car',\n",
    "                  'vehicle.construction',\n",
    "                  'vehicle.emergency.ambulance',\n",
    "                  'vehicle.emergency.police',\n",
    "                  'vehicle.motorcycle',\n",
    "                  'vehicle.trailer',\n",
    "                  'vehicle.truck']\n",
    "\n",
    "# @register_dataset\n",
    "class CustomNuscDataset(Dataset):\n",
    "    NumPointFeatures = 5\n",
    "\n",
    "    def __init__(self, root_path=NUSC_DATASET_ROOT, info_path=None,\n",
    "                 class_names=[\"movable_object.trafficcone\"], prep_func=None,\n",
    "                 num_point_features=None):\n",
    "\n",
    "        data_dir = root_path\n",
    "        json_dir = os.path.join(root_path, f'v1.0-{VERSION}')\n",
    "        print(json_dir)\n",
    "        self.class_names = class_names\n",
    "        self.nusc = NuScenes(dataroot=data_dir,version=f'v1.0-{VERSION}')\n",
    "        self._prep_func = prep_func\n",
    "        self.box_classes = set()\n",
    "        self.filtered_sample_tokens = []\n",
    "        for sample in self.nusc.sample:\n",
    "            sample_token = sample['token']\n",
    "            sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "            boxes = self.nusc.get_boxes(sample_lidar_token)\n",
    "            for box in boxes:\n",
    "                self.box_classes.add(box.name)\n",
    "                if box.name in self.class_names:\n",
    "                    self.filtered_sample_tokens.append(sample_token)\n",
    "                    break\n",
    "\n",
    "        self.split = np.arange(len(self.filtered_sample_tokens))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.split.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_dict = self.get_sensor_data(index)\n",
    "        try:\n",
    "            example = self._prep_func(input_dict=input_dict)\n",
    "            return example\n",
    "        except:\n",
    "            return input_dict\n",
    "    def __name__(self):\n",
    "        return \"CustomNuscDataset\"\n",
    "    def get_sensor_data(self, query):\n",
    "        res = {\n",
    "            'lidar': {\n",
    "                'type': 'lidar',\n",
    "                'points': None,\n",
    "            },\n",
    "            'metadata': {\n",
    "                'token': self.filtered_sample_tokens[query]\n",
    "            }\n",
    "        }\n",
    "        points = self.getPoints(query)\n",
    "        boxes_dict = self.getBoxes(query)\n",
    "\n",
    "        res['lidar']['points'] = points\n",
    "\n",
    "        gt_boxes = []\n",
    "        gt_names = []\n",
    "\n",
    "        for box in boxes_dict:\n",
    "            xyz = box.center\n",
    "            wlh = box.wlh\n",
    "            theta = quaternion_yaw(box.orientation)\n",
    "            gt_boxes.append([xyz[0], xyz[1], xyz[2], wlh[0], wlh[1], wlh[2], -theta - np.pi / 2])\n",
    "            gt_names.append(box.name)\n",
    "\n",
    "        res['lidar']['annotations'] = {\n",
    "            'boxes': np.asarray(gt_boxes,dtype=np.float32),\n",
    "            'names': gt_names,\n",
    "        }\n",
    "        return res\n",
    "\n",
    "        ###\n",
    "\n",
    "    def getPoints(self, index):\n",
    "        sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "\n",
    "        lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "        ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "        calibrated_sensor = self.nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "\n",
    "        global_from_car = transform_matrix(ego_pose['translation'],\n",
    "                                           Quaternion(ego_pose['rotation']), inverse=False)\n",
    "        car_from_sensor = transform_matrix(calibrated_sensor['translation'],\n",
    "                                           Quaternion(calibrated_sensor['rotation']), inverse=False)\n",
    "        try:\n",
    "            lidar_pointcloud, times = LidarPointCloud.from_file_multisweep(self.nusc, sample, 'LIDAR_TOP',\n",
    "                                                                           'LIDAR_TOP')\n",
    "            lidar_pointcloud.transform(car_from_sensor)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load Lidar Pointcloud for {sample}:{e}\")\n",
    "        points = lidar_pointcloud.points\n",
    "        points[3, :] /= 255\n",
    "        points[3, :] -= 0.5\n",
    "\n",
    "        points_cat = np.concatenate([points, times], axis=0).transpose()\n",
    "        points_cat = points_cat[~np.isnan(points_cat).any(axis=1)]\n",
    "\n",
    "        return points_cat\n",
    "\n",
    "    def getBoxes(self, index):\n",
    "\n",
    "        sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "        lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "        ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "\n",
    "        boxes_dict = self.nusc.get_boxes(sample_lidar_token)\n",
    "\n",
    "        keep_box_idx = []\n",
    "        for i, box in enumerate(boxes_dict):\n",
    "            if box.name in self.class_names:\n",
    "                keep_box_idx.append(i)\n",
    "\n",
    "        boxes_dict = [box for i, box in enumerate(boxes_dict) if i in keep_box_idx]\n",
    "\n",
    "        return boxes_dict\n",
    "\n",
    "    def move_boxes_to_car_space(self,boxes, ego_pose):\n",
    "        \"\"\"\n",
    "        Move boxes from world space to car space.\n",
    "        Note: mutates input boxes.\n",
    "        \"\"\"\n",
    "        translation = -np.array(ego_pose['translation'])\n",
    "        rotation = Quaternion(ego_pose['rotation']).inverse\n",
    "\n",
    "        for box in boxes:\n",
    "            # Bring box to car space\n",
    "            box.translate(translation)\n",
    "            box.rotate(rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomNuscDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/starlet/LdTho/data/sets/nuscenes/v1.0-trainval/kitti_dbinfos_train.pkl', 'rb') as infile:\n",
    "    train = pickle.load(infile)\n",
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['movable_object.trafficcone'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in train['movable_object.trafficcone'] if i['path'] == 'gt_database/0_movable_object.trafficcone_0.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pandas\n",
    "import sys\n",
    "sys.path.append('/kaggle/code/ConeDetectionPointpillars')\n",
    "import fire\n",
    "import pickle\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix, quaternion_yaw\n",
    "from second.data.dataset import Dataset, register_dataset, get_dataset_class\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from nuscenes.utils.geometry_utils import *\n",
    "from second.core import box_np_ops\n",
    "VERSION = 'trainval'\n",
    "TRAINVAL_SPLIT_PERCENTAGE = 0.999 if VERSION == 'trainval' else 0.8\n",
    "NameMapping = {\n",
    "    'movable_object.barrier': 'barrier',\n",
    "    'vehicle.bicycle': 'bicycle',\n",
    "    'vehicle.bus.bendy': 'bus',\n",
    "    'vehicle.bus.rigid': 'bus',\n",
    "    'vehicle.car': 'car',\n",
    "    'vehicle.construction': 'construction_vehicle',\n",
    "    'vehicle.motorcycle': 'motorcycle',\n",
    "    'human.pedestrian.adult': 'pedestrian',\n",
    "    'human.pedestrian.child': 'pedestrian',\n",
    "    'human.pedestrian.construction_worker': 'pedestrian',\n",
    "    'human.pedestrian.police_officer': 'pedestrian',\n",
    "    'movable_object.trafficcone': 'traffic_cone',\n",
    "    'vehicle.trailer': 'trailer',\n",
    "    'vehicle.truck': 'truck',\n",
    "    'movable_object.pushable_pullable': 'DontCare',\n",
    "    'movable_object.debris': 'DontCare'\n",
    "}\n",
    "DefaultAttribute = {\n",
    "    \"car\": \"vehicle.parked\",\n",
    "    \"pedestrian\": \"pedestrian.moving\",\n",
    "    \"trailer\": \"vehicle.parked\",\n",
    "    \"truck\": \"vehicle.parked\",\n",
    "    \"bus\": \"vehicle.parked\",\n",
    "    \"motorcycle\": \"cycle.without_rider\",\n",
    "    \"construction_vehicle\": \"vehicle.parked\",\n",
    "    \"bicycle\": \"cycle.without_rider\",\n",
    "    \"barrier\": \"\",\n",
    "    \"traffic_cone\": \"\",\n",
    "}\n",
    "\n",
    "\n",
    "# @register_dataset\n",
    "class CustomNuscDataset(Dataset):\n",
    "    NumPointFeatures = 5\n",
    "\n",
    "    def __init__(self, root_path=f'/media/starlet/LdTho/data/sets/nuscenes/v1.0-{VERSION}', info_path=None,\n",
    "                 class_names=[\"traffic_cone\"], prep_func=None,\n",
    "                 num_point_features=None):\n",
    "        self.NumPointFeatures = 5\n",
    "        self.class_names = class_names\n",
    "        self.nusc = NuScenes(dataroot=root_path, version=f'v1.0-{VERSION}')\n",
    "        self._prep_func = prep_func\n",
    "        self.filtered_sample_tokens = []\n",
    "        for sample in self.nusc.sample:\n",
    "            sample_token = sample['token']\n",
    "            sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "            boxes = self.nusc.get_boxes(sample_lidar_token)\n",
    "            box_names = [NameMapping[b.name] for b in boxes if b.name in NameMapping.keys()]\n",
    "            for box in boxes:\n",
    "                if box.name not in NameMapping.keys():\n",
    "                    continue\n",
    "                # if NameMapping[box.name] in self.class_names:\n",
    "                if (NameMapping[box.name] in [\"traffic_cone\"]) & (box_names.count('traffic_cone') > 8):\n",
    "                    self.filtered_sample_tokens.append(sample_token)\n",
    "                    break\n",
    "        self.filtered_sample_tokens = self.filtered_sample_tokens[\n",
    "                                      :round(len(self.filtered_sample_tokens) * TRAINVAL_SPLIT_PERCENTAGE)]\n",
    "\n",
    "        self.split = np.arange(len(self.filtered_sample_tokens))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.split.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_dict = self.get_sensor_data(index)\n",
    "        example = self._prep_func(input_dict=input_dict)\n",
    "        example[\"metadata\"] = input_dict[\"metadata\"]\n",
    "        if \"anchors_mask\" in example:\n",
    "            example[\"anchors_mask\"] = example[\"anchors_mask\"].astype(np.uint8)\n",
    "        return example\n",
    "\n",
    "    def get_sensor_data(self, query, token = None):\n",
    "        res = {\n",
    "            'lidar': {\n",
    "                'type': 'lidar',\n",
    "                'points': None,\n",
    "            },\n",
    "            'metadata': {\n",
    "                'token': self.filtered_sample_tokens[query]\n",
    "            }\n",
    "        }\n",
    "        if token:\n",
    "            query = self.filtered_sample_tokens.index(token)\n",
    "        points = self.getPoints(query)\n",
    "        boxes_dict = self.getBoxes(query)\n",
    "\n",
    "        res['lidar']['points'] = points\n",
    "\n",
    "        gt_boxes = []\n",
    "        gt_names = []\n",
    "\n",
    "        for box in boxes_dict:\n",
    "            xyz = box.center\n",
    "            wlh = box.wlh\n",
    "            theta = quaternion_yaw(box.orientation)\n",
    "            gt_boxes.append([xyz[0], xyz[1], xyz[2], wlh[0], wlh[1], wlh[2], -theta - np.pi / 2])\n",
    "            gt_names.append(box.name)\n",
    "        gt_boxes = np.concatenate(gt_boxes).reshape(-1, 7)\n",
    "        gt_names = np.array(gt_names)\n",
    "        res['lidar']['annotations'] = {\n",
    "            'boxes': gt_boxes,\n",
    "            'names': gt_names,\n",
    "        }\n",
    "        return res\n",
    "\n",
    "        ###\n",
    "\n",
    "    def getPoints(self, index):\n",
    "        sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "\n",
    "        lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "        ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "        calibrated_sensor = self.nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "\n",
    "        global_from_car = transform_matrix(ego_pose['translation'],\n",
    "                                           Quaternion(ego_pose['rotation']), inverse=False)\n",
    "        car_from_sensor = transform_matrix(calibrated_sensor['translation'],\n",
    "                                           Quaternion(calibrated_sensor['rotation']), inverse=False)\n",
    "        try:\n",
    "            lidar_pointcloud, times = LidarPointCloud.from_file_multisweep(self.nusc, sample, 'LIDAR_TOP',\n",
    "                                                                           'LIDAR_TOP')\n",
    "            lidar_pointcloud.transform(car_from_sensor)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load Lidar Pointcloud for {sample}:{e}\")\n",
    "        points = lidar_pointcloud.points\n",
    "        points[3, :] /= 255\n",
    "        points[3, :] -= 0.5\n",
    "\n",
    "        points_cat = np.concatenate([points, times], axis=0).transpose()\n",
    "        points_cat = points_cat[~np.isnan(points_cat).any(axis=1)]\n",
    "\n",
    "        return points_cat\n",
    "\n",
    "    def getBoxes(self, index):\n",
    "\n",
    "        sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "        lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "        ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "\n",
    "        boxes_dict = self.nusc.get_boxes(sample_lidar_token)\n",
    "\n",
    "        keep_box_idx = []\n",
    "        for i, box in enumerate(boxes_dict):\n",
    "            if box.name not in NameMapping.keys():\n",
    "                continue\n",
    "            if NameMapping[box.name] in self.class_names:\n",
    "                box.name = NameMapping[box.name]\n",
    "                keep_box_idx.append(i)\n",
    "\n",
    "        boxes_dict = [box for i, box in enumerate(boxes_dict) if i in keep_box_idx]\n",
    "        self.move_boxes_to_car_space(boxes_dict, ego_pose)\n",
    "        # print(boxes_dict)\n",
    "        return boxes_dict\n",
    "\n",
    "    def move_boxes_to_car_space(self, boxes, ego_pose):\n",
    "        \"\"\"\n",
    "        Move boxes from world space to car space.\n",
    "        Note: mutates input boxes.\n",
    "        \"\"\"\n",
    "        translation = -np.array(ego_pose['translation'])\n",
    "        rotation = Quaternion(ego_pose['rotation']).inverse\n",
    "\n",
    "        for box in boxes:\n",
    "            # Bring box to car space\n",
    "            box.translate(translation)\n",
    "            box.rotate(rotation)\n",
    "\n",
    "\n",
    "# @register_dataset\n",
    "class CustomNuscTestDataset(Dataset):\n",
    "    NumPointFeatures = 5\n",
    "\n",
    "    def __init__(self, root_path=f'/media/starlet/LdTho/data/sets/nuscenes/v1.0-{VERSION}',\n",
    "                 info_path=None,\n",
    "                 class_names=['traffic_cone'],\n",
    "                 prep_func=None,\n",
    "                 num_point_features=None,\n",
    "                 multi_test=False):\n",
    "        print(root_path)\n",
    "        self.nusc = NuScenes(dataroot=root_path, version=f'v1.0-{VERSION}')\n",
    "        self.class_names = class_names\n",
    "        self._prep_func = prep_func\n",
    "        self.filtered_sample_tokens = []\n",
    "        self.multi_test = multi_test\n",
    "        for sample in self.nusc.sample:\n",
    "            sample_token = sample['token']\n",
    "            sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "            boxes = self.nusc.get_boxes(sample_lidar_token)\n",
    "            for box in boxes:\n",
    "                # self.box_classes.add(box.name\n",
    "                if box.name not in NameMapping.keys():\n",
    "                    continue\n",
    "                if NameMapping[box.name] in self.class_names:\n",
    "                    self.filtered_sample_tokens.append(sample_token)\n",
    "                    break\n",
    "        self.filtered_sample_tokens = self.filtered_sample_tokens[\n",
    "                                      round(len(self.filtered_sample_tokens) * TRAINVAL_SPLIT_PERCENTAGE):]\n",
    "        self.split = np.arange(len(self.filtered_sample_tokens))\n",
    "        self.num_samples = len(self.filtered_sample_tokens)\n",
    "        self.rot = 0.0\n",
    "        self.scale = 1.0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_dict = self.get_sensor_data(index)\n",
    "        example = self._prep_func(input_dict=input_dict)\n",
    "        example[\"metadata\"] = input_dict[\"metadata\"]\n",
    "        if \"anchors_mask\" in example:\n",
    "            example[\"anchors_mask\"] = example[\"anchors_mask\"].astype(np.uint8)\n",
    "        return example\n",
    "\n",
    "    def get_sensor_data(self, query):\n",
    "        res = {\n",
    "            'lidar': {\n",
    "                'type': 'lidar',\n",
    "                'points': None\n",
    "            },\n",
    "            'metadata': {\n",
    "                'token': self.filtered_sample_tokens[query],\n",
    "            }\n",
    "        }\n",
    "        points = self.getPoints(query)\n",
    "        res['lidar']['points'] = points\n",
    "        return res\n",
    "\n",
    "    def getPoints(self, query):\n",
    "        sample = self.nusc.get('sample', self.filtered_sample_tokens[query])\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "\n",
    "        lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "        ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "        calibrated_sensor = self.nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "\n",
    "        global_from_car = transform_matrix(ego_pose['translation'],\n",
    "                                           Quaternion(ego_pose['rotation']), inverse=False)\n",
    "        car_from_sensor = transform_matrix(calibrated_sensor['translation'],\n",
    "                                           Quaternion(calibrated_sensor['rotation']), inverse=False)\n",
    "        try:\n",
    "            lidar_pointcloud, times = LidarPointCloud.from_file_multisweep(self.nusc, sample, 'LIDAR_TOP', 'LIDAR_TOP')\n",
    "            lidar_pointcloud.transform(car_from_sensor)\n",
    "        except Exception as e:\n",
    "            print(f\"failed to load pointcloud for {sample}: {e}\")\n",
    "        points = lidar_pointcloud.points\n",
    "        points[3, :] /= 255\n",
    "        points[3, :] -= 0.5\n",
    "        points_cat = np.concatenate([points, times], axis=0).transpose()\n",
    "        points_cat = points_cat[~np.isnan(points_cat).any(axis=1)]\n",
    "        return points_cat\n",
    "\n",
    "    def evaluation(self, detections, output_dir):\n",
    "        res_custom_nusc = self.evaluation_custom_nusc(detections, output_dir)\n",
    "        res = {\n",
    "            \"results\":{\n",
    "                \"nusc\": res_custom_nusc[\"results\"][\"nusc\"],\n",
    "            },\n",
    "            \"details\":{\n",
    "                \"eval.nusc\": res_custom_nusc[\"detail\"][\"nusc\"]\n",
    "            }\n",
    "        }\n",
    "        return res\n",
    "    def evaluation_custom_nusc(self, detections, output_dir):\n",
    "        pass\n",
    "\n",
    "\n",
    "# should shorten by inherit from parent class CustomNuscDataset\n",
    "# @register_dataset\n",
    "class CustomNuscEvalDataset(Dataset):\n",
    "    NumPointFeatures = 5\n",
    "\n",
    "    def __init__(self, root_path=f'/media/starlet/LdTho/data/sets/nuscenes/v1.0-mini', info_path=None,\n",
    "                 class_names=[\"traffic_cone\"], prep_func=None,\n",
    "                 num_point_features=None):\n",
    "        self.NumPointFeatures = 5\n",
    "        self.class_names = class_names\n",
    "        self.nusc = NuScenes(dataroot=root_path, version=f'v1.0-mini')\n",
    "        self._prep_func = prep_func\n",
    "        self.filtered_sample_tokens = []\n",
    "        for sample in self.nusc.sample:\n",
    "            sample_token = sample['token']\n",
    "            sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "            boxes = self.nusc.get_boxes(sample_lidar_token)\n",
    "            box_names = [b.name for b in boxes if b.name in NameMapping.keys()]\n",
    "            for box in boxes:\n",
    "                # self.box_classes.add(box.name\n",
    "                if box.name not in NameMapping.keys():\n",
    "                    continue\n",
    "                # if NameMapping[box.name] in self.class_names:\n",
    "                if (NameMapping[box.name] in [\"traffic_cone\"]) & (box_names.count('traffic_cone') > 7):\n",
    "                    print(box_names)\n",
    "                    self.filtered_sample_tokens.append(sample_token)\n",
    "                    break\n",
    "        self.filtered_sample_tokens = self.filtered_sample_tokens[\n",
    "                                      :round(len(self.filtered_sample_tokens) * TRAINVAL_SPLIT_PERCENTAGE)]\n",
    "\n",
    "        self.split = np.arange(len(self.filtered_sample_tokens))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.split.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_dict = self.get_sensor_data(index)\n",
    "        example = self._prep_func(input_dict=input_dict)\n",
    "        example[\"metadata\"] = input_dict[\"metadata\"]\n",
    "        if \"anchors_mask\" in example:\n",
    "            example[\"anchors_mask\"] = example[\"anchors_mask\"].astype(np.uint8)\n",
    "        return example\n",
    "\n",
    "    def get_sensor_data(self, query, token = None):\n",
    "        res = {\n",
    "            'lidar': {\n",
    "                'type': 'lidar',\n",
    "                'points': None,\n",
    "            },\n",
    "            'metadata': {\n",
    "                'token': self.filtered_sample_tokens[query]\n",
    "            }\n",
    "        }\n",
    "        if token:\n",
    "            query = self.filtered_sample_tokens.index(token)\n",
    "        points = self.getPoints(query)\n",
    "        boxes_dict = self.getBoxes(query)\n",
    "\n",
    "        res['lidar']['points'] = points\n",
    "\n",
    "        gt_boxes = []\n",
    "        gt_names = []\n",
    "\n",
    "        for box in boxes_dict:\n",
    "            xyz = box.center\n",
    "            wlh = box.wlh\n",
    "            theta = quaternion_yaw(box.orientation)\n",
    "            gt_boxes.append([xyz[0], xyz[1], xyz[2], wlh[0], wlh[1], wlh[2], -theta - np.pi / 2])\n",
    "            gt_names.append(box.name)\n",
    "        gt_boxes = np.concatenate(gt_boxes).reshape(-1, 7)\n",
    "        gt_names = np.array(gt_names)\n",
    "        res['lidar']['annotations'] = {\n",
    "            'boxes': gt_boxes,\n",
    "            'names': gt_names,\n",
    "        }\n",
    "        return res\n",
    "\n",
    "        ###\n",
    "\n",
    "    def getPoints(self, index):\n",
    "        sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "\n",
    "        lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "        ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "        calibrated_sensor = self.nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "\n",
    "        global_from_car = transform_matrix(ego_pose['translation'],\n",
    "                                           Quaternion(ego_pose['rotation']), inverse=False)\n",
    "        car_from_sensor = transform_matrix(calibrated_sensor['translation'],\n",
    "                                           Quaternion(calibrated_sensor['rotation']), inverse=False)\n",
    "        try:\n",
    "            lidar_pointcloud, times = LidarPointCloud.from_file_multisweep(self.nusc, sample, 'LIDAR_TOP',\n",
    "                                                                           'LIDAR_TOP')\n",
    "            lidar_pointcloud.transform(car_from_sensor)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load Lidar Pointcloud for {sample}:{e}\")\n",
    "        points = lidar_pointcloud.points\n",
    "        points[3, :] /= 255\n",
    "        points[3, :] -= 0.5\n",
    "\n",
    "        points_cat = np.concatenate([points, times], axis=0).transpose()\n",
    "        points_cat = points_cat[~np.isnan(points_cat).any(axis=1)]\n",
    "\n",
    "        return points_cat\n",
    "\n",
    "    def getBoxes(self, index):\n",
    "\n",
    "        sample = self.nusc.get('sample', self.filtered_sample_tokens[index])\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "        lidar_data = self.nusc.get('sample_data', sample_lidar_token)\n",
    "        ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])\n",
    "\n",
    "        boxes_dict = self.nusc.get_boxes(sample_lidar_token)\n",
    "\n",
    "        keep_box_idx = []\n",
    "        for i, box in enumerate(boxes_dict):\n",
    "            if box.name not in NameMapping.keys():\n",
    "                continue\n",
    "            if NameMapping[box.name] in self.class_names:\n",
    "                box.name = NameMapping[box.name]\n",
    "                keep_box_idx.append(i)\n",
    "\n",
    "        boxes_dict = [box for i, box in enumerate(boxes_dict) if i in keep_box_idx]\n",
    "        self.move_boxes_to_car_space(boxes_dict, ego_pose)\n",
    "        # print(boxes_dict)\n",
    "        return boxes_dict\n",
    "\n",
    "    def move_boxes_to_car_space(self, boxes, ego_pose):\n",
    "        \"\"\"\n",
    "        Move boxes from world space to car space.\n",
    "        Note: mutates input boxes.\n",
    "        \"\"\"\n",
    "        translation = -np.array(ego_pose['translation'])\n",
    "        rotation = Quaternion(ego_pose['rotation']).inverse\n",
    "\n",
    "        for box in boxes:\n",
    "            # Bring box to car space\n",
    "            box.translate(translation)\n",
    "            box.rotate(rotation)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     fire.Fire()\n",
    "    # train_data = CustomNuscDataset()\n",
    "    # test_data = CustomNuscTestDataset(root_path='/media/starlet/LdTho/data/sets/nuscenes/v1.0-trainval',\n",
    "    #                                   )\n",
    "#     print(train_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomNuscDataset(root_path = '/media/starlet/LdTho/data/sets/nuscenes/v1.0-trainval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, l, h = 0,0,0\n",
    "\n",
    "for i in tqdm_notebook(range(len(test_dataset))):\n",
    "    for box in test_dataset[i]['lidar']['annotations']['boxes']:\n",
    "        w = max(w, box[3])\n",
    "        l = max(l, box[4])\n",
    "        h = max(h, box[5])\n",
    "print(w,l,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, l, h = [],[],[]\n",
    "x, y, z = [],[],[]\n",
    "for i in tqdm_notebook(range(len(test_dataset))):\n",
    "    for box in test_dataset[i]['lidar']['annotations']['boxes']:\n",
    "        x.append(box[0])\n",
    "        y.append(box[1])\n",
    "        z.append(box[3])       \n",
    "        w.append(box[3])\n",
    "        l.append(box[4])\n",
    "        h.append(box[5])\n",
    "# print(w,l,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[i]['lidar']['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
